<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Pan'Log</title><meta name=keywords content><meta name=description content="Posts - Pan'Log"><meta name=author content="Pan"><link rel=canonical href=https://payne4handsome.github.io/posts/><link crossorigin=anonymous href=/assets/css/stylesheet.7140587df96a2b1a49eb723fa7063dc0c641a6cb638f3140e8d3beb4deae4f5c.css integrity="sha256-cUBYfflqKxpJ63I/pwY9wMZBpstjjzFA6NO+tN6uT1w=" rel="preload stylesheet" as=style><link rel=icon href=https://payne4handsome.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://payne4handsome.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://payne4handsome.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://payne4handsome.github.io/apple-touch-icon.png><link rel=mask-icon href=https://payne4handsome.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://payne4handsome.github.io/posts/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Posts"><meta property="og:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><meta property="og:type" content="website"><meta property="og:url" content="https://payne4handsome.github.io/posts/"><meta property="og:image" content="https://payne4handsome.github.io/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://payne4handsome.github.io/papermod-cover.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://payne4handsome.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://payne4handsome.github.io accesskey=h title="Pan'Log (Alt + H)">Pan'Log</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://payne4handsome.github.io/posts/ title=Posts><span class=active>Posts</span></a></li><li><a href=https://payne4handsome.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://payne4handsome.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://payne4handsome.github.io/archives title=Archive><span>Archive</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://payne4handsome.github.io>主页</a></div><h1>Posts</h1></header><article class=post-entry><header class=entry-header><h2>nvidia smi docker usage</h2></header><div class=entry-content><p>正文 docker 和 nvidia-docker命令的区别
如果容器中需要用到cuda，但是使用docker 启动是找不到cuda的，nvidia-smi命令也无法使用。必须使用nvidia-docker启动。经试验，如下命令也是ok的，docker指定参数 –gpus
docker run --rm --gpus all nvidia/cuda nvidia-smi 指定使用那一块GPU
使用全部的gpu docker run --rm --gpus all nvidia/cuda nvidia-smi 使用环境变量NVIDIA_VISIBLE_DEVICES来指定使用那一个GPU（必须指定runtime，–runtime=nvidia） docker run --rm --runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=all nvidia/cuda nvidia-smi 容器内可以使用两块gpu docker run --rm --gpus 2 nvidia/cuda nvidia-smi 指定gpu编号 docker run --gpus '"device=1,2"' nvidia/cuda nvidia-smi --query-gpu=uuid --format-csv [参考文档] https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html nvidia-docker2 安装</p></div><footer class=entry-footer>1 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to nvidia smi docker usage" href=https://payne4handsome.github.io/posts/basic/nvidia-smi-docker-usage/></a></article><article class=post-entry><header class=entry-header><h2>TLS</h2></header><div class=entry-content><p>本文借助wireshark抓包详细的讲解SSL/TLS协议。HTTPS是为了解决http报文明文传输过程中的安全问题。HTTPS是“HTTP over SSL”的缩写。所以要了解HTTPS就必须先了解SSL/TLS协议。
一、HTTP协议的风险 HTTP协议中所有消息都是明文传播，存在如下三大风险
窃听风险（eavesdropping）：第三方可以获知通信内容。 篡改风险（tampering）：第三方可以修改通信内容。 冒充风险（pretending）：第三方可以冒充他人身份参与通信。 为了解决这个三个风险，分别对应如下三个解决方案。
加密：所有信息都是加密传播，第三方无法窃听。 校验：具有校验机制，一旦被篡改，通信双方会立刻发现。 身份验证：配备身份证书，防止身份被冒充。 二、SSL/TLS 发展历史 1994年，NetScape公司设计了SSL协议（Secure Sockets Layer）的1.0版，但是未发布。 1995年，NetScape公司发布SSL 2.0版，很快发现有严重漏洞。 1996年，SSL 3.0版问世，得到大规模应用。 1999年，互联网标准化组织ISOC接替NetScape公司，发布了SSL的升级版TLS 1.0版。 2006: TLS 1.1. 作为 RFC 4346 发布。主要fix了CBC模式相关的如BEAST攻击等漏洞。 2008: TLS 1.2. 作为RFC 5246 发布 。增进安全性。目前(2015年)应该主要部署的版本。 2015之后: TLS 1.3，还在制订中，支持0-rtt，大幅增进安全性，砍掉了aead之外的加密方式。 由于SSL的2个版本都已经退出历史舞台了，所以本文后面只用TLS这个名字。 一般所说的SSL就是TLS。
三、报文解析(rfc5246) TLS建立连接的过程如下图，先有个大概的印象，后面我们再详细分析。整个需要四次握手。 SSL/TLS工作在应用层和传输层之间，在建立连接的之前需要先建立TCP连接（三次握手），如下图。 3.1 详细过程 （1）Client Hello 从截图中可以看出TLS协议分为两个部分记录协议（Record Layer）和握手协议（Handshake Protocal）。
3.1.1 记录协议（Record Layer） 记录协议根据rfc描述记录协议（Record Layer）有如下4种类型，即上图中Content Type可以取的值。
记录协议（Record Layer） 数据结构 对照着wireshark抓包为：Content Type：Handshake(22), Version: TLS 1.0(0x0301), Length: 512
3.1.2 握手协议（Handshake Protocal） 握手协议（Handshake Protocal）有如下10种类型。 握手协议（Handshake Protocal）数据结构 对照着wireshark抓包为：Handshake Type: Client Hello, Length: 508, Version : TLS 1....</p></div><footer class=entry-footer>1 分钟&nbsp;·&nbsp;pan</footer><a class=entry-link aria-label="post link to TLS" href=https://payne4handsome.github.io/posts/compute-network/tls/></a></article><article class=post-entry><header class=entry-header><h2>Transformer研究综述</h2></header><div class=entry-content><p>一、基础部分 2017年google发表了一篇All Attention Is All You Need论文, 在机器翻译任务中取得了SOTA 的成绩。论文中提出的Transformer结构取消了传统的Seg2Seg模型中RNN和CNN传统神经网络单元，取而代之代之的Self-Attention（自注意力机制）的计算单元。该计算单元并行化程度高，训练时间短。所以Transformer引起了学术界和工业界的广泛注意。目前已经是NLP领域的标配。随后在2019年google提出基本Transformer的bert模型, 该模型在大量的数据集中通过自监督的训练，然后在特定任务上只需要做少量改动和训练就可以得到非常好的效果，开源的bert模型在11个NLP任务取得SOTA结果。
Transformer除了在NLP任务上表现优异，在CV领域也取得了很多突破。2020年google又发表了一篇 VIT Transformer的论文，实验证明Transformer在imagenet分类任务上取得了SOTA结果。后来CV领域中的各种基本问题，比如目标检测、语义分割、物体追踪、视频等各种任务都用Transformer方法又搞了一遍，基本上也取得了一些不错的结果。
鉴于Transformer在NLP和CV上的巨大成功，本文竟可能详细描述Transformer的基本原理；特定的一些应用，主要是一些经典论文的方法；以及目前Transformer在效率问题上的一些改进的方案。
1.1 Attention 在学习Transformer之前，了解一些基础问题是很有必要。毕竟在没有Transformer之前，学术上在NLP领域也做了大量的研究和成果。我们先从Encoder Decoder和Seq2Seq开始说起。我想大家肯定都听过这两个名称，简单来说就是如下图。 Encoder输入（可以是文字也可以是图像）编程成一个固定长度的向量（content）,那么这个content向量肯定是包含输入的信息的（至于包含多少那就看这个编码了），Decoder根据content解码出我们需要的结果。Encoder Decoder可以是机器翻译问题、语义分割问题等等。那么Seq2Seq（Sequence-to-sequence ）是什么？输入一个序列，输出另一个序列。这种结构最重要的地方在于输入序列和输出序列的长度是可变的。如下图所示。
从本质上看，Encoder-Decoder和seq2seq好像差不多，但是又有一点区别。
Seq2Seq 属于 Encoder-Decoder 的大范畴 Seq2Seq 更强调目的，Encoder-Decoder 更强调方法 那么这个Encoder-Decoder有什么缺陷呢？
从上面的示意图我们看到，无论输入的信息又多少，Encoder后就剩下一个content向量了，那么这里面有一个缺陷就是这个content向量会丢掉一些信息，特别是输入很大（文本很长图像分辨率很高）的情况下。尽管后面出现的LSTM、GRU等通过门设计的循环神经网络单元，可以一定程度上缓解长距离问题，但是效果有限。
从这里开始，我们要进入文章的正题了，Transformer的核心是Self-Attention，那么在这之前，我们最起码要了解什么是Attention，然后再看是这么在 Attention的基础上加上self的。
1.1.1 NLP中的Attention 由于传统的Encoder-Decoder模型将所有的输入信息编码成一个固定长度的content向量存在长距离问题。那么随之而然的一个做法就是我们在decoder阶段解码$h_t$不仅依赖前一个节点的隐藏状态$h_{t-1}$, 同时依赖Encoder阶段所有的状态，就和我们自已翻译的时候一样。这里有两个经典注意力机制，Bahdanau Attention （2014年提出）和 Luong Attention（2015年）。
1.1.1.1 Bahdanau Attention 注意力机制 示意图如下： 假设现在我们Decoder t时刻。 那么$h_t$隐状态计算过程如下：
计算对齐向量$a_t$
$a_t$的长度与Encoder输出向量的个数相同。$a_t(s)$表示Decoder阶段的转态$h_{t-1}$与Encoder阶段第s个隐状态，通过align对齐函数计算出的一个权重。$a_t$就是$h_{t-1}与每一个Encoder隐状态计算权重后组成的一个向量。
计算$c_t$即content vector
将上一步计算出的$a_t$向量乘以Encoder所有的隐向量。即Encoder所有的隐向量的加权和。
计算Decoder阶段t时刻的输出，$h_t$
将$h^{l-1}{t-1}$与concat（$c_t$， $h{t-1}$）送入多层RNN（最后一层）。其中$h^{l-1}{t-1}$为上一阶段的预测输出。concat（$c_t$， $h{t-1}$）相当于RNN的隐状态。最终将$h_t$过一个softmax就可以预测最终的输出（$y^t$）了。
1.1.1.2 Luong Attention 注意力机制 Luong Attention是在Bahdanau Attention之后提出的。结构更加简洁，效果也更加好一点。 假设现在我们Decoder t时刻。 那么$h_t$隐状态计算过程如下：
计算对齐向量$a_t$
$a_t$的长度与Encoder输出向量的个数相同。$a_t(s)$表示Decoder阶段的状态$h_t$与Encoder阶段第s个隐状态，通过align对齐函数计算出的一个权重。$a_t$就是$h_t$与每一个Encoder隐状态计算权重后组成的一个向量。...</p></div><footer class=entry-footer>4 分钟&nbsp;·&nbsp;Pan</footer><a class=entry-link aria-label="post link to Transformer研究综述" href=https://payne4handsome.github.io/posts/machine-learning/transformer%E7%A0%94%E7%A9%B6%E7%BB%BC%E8%BF%B0/></a></article><article class=post-entry><header class=entry-header><h2>VAE</h2></header><div class=entry-content><p>Vanilla VAE(Variational Autoencoder) 一、AutoEncoder 回顾 生成模型 最理想的生成就是知道输入样本的分布$P(X)$, 然后我们并不知道该分布。那么可以近似求解。 $P(X) = \Sigma P(X|Z)*P(Z)$。但$P(X|Z), P(Z)$我们同样不知道。但是我们可以用神经网络去学习这两个分布。上图中的latent vector可以看成是$P(Z)$的一个采样，decoder可以看成条件概率$P(X|Z)$。但是我们真的可以采样一个z，然后用加一个decoder来作为我们的生成模型吗？
z是Encoder对应着样本X的输出，如果我们直接用Decoder对z还原，那么最终得到的$\hat{X}$是和X是差不多的，我们需要生成模型是生成一个和X类似的，而不是一模一样的 如果对z做一些扰动，必然加一些噪声，那是不是就可以生成类似但是不一样的东西呢？理论上是可以，但是到目前为止，我们的模型并没有保证这一点（模型还没有学习） 加噪声是一个好的思路，如何加噪声？
让z从一个分布采样（注意不是直接使用encoder的输出），就是噪声。 那不放让z从一个$N(u, \sigma^2)$中采样。那需要知道$u, \sigma^2$, 既然不知道那就用神经网络生成吧。 如果我们按照上述去训练我们的模型，生成方差$\sigma^2$的回倾向于变成0（因为容易学）。那如何加以限制？使z倾向于一个标准正态分布，即$\sigma^2$倾向于1。 如下图 如何监督模型达到该目的，KL loss作为监督信号，KL loss如下 reparameterization trick 思考？ 为什么要正态分布、其它分布可否？ ….. 待补充完善 参考文献 Auto-Encoding Variational Bayes Tutorial on Variational Autoencoders 变分自编码器 李宏毅深度生成模型</p></div><footer class=entry-footer>1 分钟&nbsp;·&nbsp;Pan</footer><a class=entry-link aria-label="post link to VAE" href=https://payne4handsome.github.io/posts/machine-learning/vae/></a></article><article class=post-entry><header class=entry-header><h2>机器学习基础之交叉熵和MSE</h2></header><div class=entry-content><p>机器学习基础之交叉熵与均方误差 我们都知道，对于分类任务，可以选用交叉熵做为模型的损失函数；对于回归任务，可以选用MSE来作为模型的损失函数。那么分类任务能否选用MSE来做为损失函数；回归任务能否选用交叉熵来作为损失函数呢？ 本文只能尽可能尝试回答这个问题，帮助大家有个大概的认识，目前尚无法对其做严格的数学证明。如果大家看到对这个问题有很好的数学证明，欢迎讨论
符号定义：
$N$: 类别数量
$y_i$: 样本onehot编码后label
$p_i$: 模型预测第i个类别的输出
那么可以用交叉熵和MSE来衡量真值和模型预测结果的偏差。公式如下：
交叉熵：$loss_{cross_entropy}=-\sum_i^N y_ilog(p_i)$
MSE: $\frac{1}{N}\sum_i^N (y_i-p_i)^2$
CE是多项式分布的最大似然；
一、为什么分类任务用交叉熵，不能用MSE 1.1 直观感受 假设真实标签为（1,0,0），预测结果一是（0.8,0.1,0.1）, 二是（0.8,0.15,0.05）。那么这两个预测哪个更好一点呢？ 两个预测结果的交叉熵都是$-log0.8=0.223$, 预测一的MSE=0.02, 预测二MSE=0.025。 即MSE任务预测一的结果要好于预测二。MSE潜在的会让预测结果除真实标签以后的标签趋于平均分布。但是实际上我们不能主观的认为预测结果一好于二。
1.2 凹凸性角度 1.2.1 使用sigmod激活、或者softmax，MSE是非凸的 我们知道，如果一个优化问题是凸优化，那么我们是可以找到全局最优解的。但是如果问题是非凸的，那么很有可能找的解是sub-optimal的。 我们用desmos（一个非常好的画图工具）画一个图来说明，对于分类问题，如果用MSE来作为损失函数，它的函数图像是非凸的。 这个例子使用了7个样本，每个样本只具有单个特征。我们可以看到函数图像是非凸的。
在参考文献3中，作者也给出了简单的数学证明，过程如下： 但是以上证明只是证明了最简单的情况（逻辑回归），且只有一个参数$\theta$的情况，如果要证明多元函数是凸的，需要证明黑塞矩阵的正定的，这个很难证明
1.2.2 交叉熵是凸的 还以逻辑回归为例。
$z = wx+b\ a=\sigma(z)\ P(Y=1;w)=a, P(Y=0;w)=1-a$
$\sigma=\frac{1}{1+e^(-x)}$是激活函数
交叉熵为$J(w)=-[y_ilog(a)+(1-y_i)log(1-a)]$
$\frac{\partial J(w)}{\partial w}=-x(y_i-a)$
$\frac{\partial^2 J(w)}{\partial w^2}=-x[-a*(1-a)x]=x^2a*(1-a)$, 其中$a \in (0,1)$, 所以交叉熵的二阶导是大于等于0的。所以交叉熵是凸的。 注意上述证明是特例证明，非严格证明
1.3 参数估计角度 交叉熵多项式分布的极大似然估计
对于样本${(x_1,y_1), (x_2, y_2), …,(x_N, y_N)}$，使用逻辑回归来分类，那么这批样本的极大似然估计可以用如下式子表达，其中a(x)是sigmod激活
$L(w)=\prod_{i=1}^N(a_w(x_i))^{y_i}(1-a_w(x_i))^{1-y_i}$$
对数似然如下：
$ln(L(w))=\sum_{i=1}^N[y_iln(a(x_i))+(1-y_i)ln(1-a(x_i))]$
上述式子是不是很眼熟，其实就是交叉熵。
其实，对于分类任务不能用MSE的原因是分类需要用sigmod或者softmax来作为激活函数，导致了MSE变成了非凸的函数...</p></div><footer class=entry-footer>1 分钟&nbsp;·&nbsp;Pan</footer><a class=entry-link aria-label="post link to 机器学习基础之交叉熵和MSE" href=https://payne4handsome.github.io/posts/machine-learning/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E4%B9%8B%E4%BA%A4%E5%8F%89%E7%86%B5%E5%92%8Cmse/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://payne4handsome.github.io/posts/page/5/>«&nbsp;上一页&nbsp;</a>
<a class=next href=https://payne4handsome.github.io/posts/page/7/>下一页&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2023 <a href=https://payne4handsome.github.io>Pan'Log</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>